{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Chr Y Full Haplogroups in LBD Cases and Controls\n",
    "- **Author(s)** - Frank Grenn\n",
    "- **Date Started** - March  2021\n",
    "- **Quick Description:** logistic regression for full haplogroups with AMPPD LBD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRKDIR = \"$PATH/chrY\"\n",
    "BFILEDIR = f\"{WRKDIR}/y_male_only_bfiles\"\n",
    "OUTDIR = f\"{WRKDIR}/output_male_hemizygous_only_het_filter_run\"\n",
    "\n",
    "#count cutoff for testing\n",
    "cutoff = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam = pd.read_csv(f\"{BFILEDIR}/amppd_lbd_case_control_nogcs.fam\",sep=\"\\s+\",header=None)\n",
    "fam.columns = ['fid','iid','pid','mid','sex','pheno']\n",
    "#-9 is for lbd (cases) in this file\n",
    "fam.loc[fam.pheno==-9,'pheno']=2\n",
    "print(fam.shape)\n",
    "print(fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam.pheno.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_pcs = pd.read_csv(f\"{BFILEDIR}/amppd_lbd_case_control_autosome_pcs.eigenvec\",sep=\"\\s+\",header=None)\n",
    "auto_pcs.columns = ['fid','iid'] + ['pc'+str(n) for n in range(1,21)]\n",
    "print(auto_pcs.shape)\n",
    "print(auto_pcs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"$PATH/AMPPD_releasev2_covariates_Feb2021.csv\")\n",
    "print(meta.shape)\n",
    "print(meta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge\n",
    "merge1 = pd.merge(left = fam[['fid','iid','sex','pheno']], right = auto_pcs, left_on = ['fid','iid'], right_on = ['fid','iid'])\n",
    "print(merge1.shape)\n",
    "merge2 = pd.merge(left = merge1, right = meta[['ID','AGE_BASELINE','LATEST_DX']], left_on = ['fid'], right_on = ['ID'])\n",
    "print(merge2.shape)\n",
    "meta_merge = merge2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_merge.LATEST_DX.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yhaplo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just get yhaplo data for now because first character of haplogroup for all samples is the same between the yhaplo and snappy tools\n",
    "yhaplo = pd.read_csv(f\"{OUTDIR}/output_yhaplo/haplogroups.chrY_male_hemizygous_only_het_filter_hg19_final.txt\",sep=\"\\s+\",header=None)\n",
    "yhaplo.columns = ['id','haplo_short','haplo_short_rep_snp','haplo_long']\n",
    "yhaplo['haplo_major'] = yhaplo['haplo_long'].str[0]\n",
    "yhaplo['id'] = [i[:len(i)//2] for i in yhaplo.id]\n",
    "print(yhaplo.shape)\n",
    "print(yhaplo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhaplo_case_control_no_gc = pd.merge(left = yhaplo[['id','haplo_long','haplo_major']], right = meta_merge,left_on = 'id', right_on = \"fid\")\n",
    "print(yhaplo_case_control_no_gc.shape)\n",
    "print(yhaplo_case_control_no_gc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhaplo_case_control_no_gc.haplo_major.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snappy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snappy = pd.read_csv(f\"{OUTDIR}/chrY_hgs_snappy_matches.out\",sep=\"\\t\",header=None)\n",
    "snappy.columns = ['id','haplo','haplo_score','info_alleles']\n",
    "\n",
    "#some samples, like \"PD-PDNZ095VCJ\" have extra data in the \"haplo\" column, like \"B2a1a M109,M152/Page60,P32,P50\", and we only want the \"B2a1a\"\n",
    "snappy['haplo']= snappy['haplo'].str.split(\" \").str[0]\n",
    "snappy['haplo_major'] = snappy['haplo'].str[0]\n",
    "print(snappy.shape)\n",
    "print(snappy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snappy_case_control_no_gc = pd.merge(left = snappy[['id','haplo','haplo_major']], right = meta_merge,left_on = 'id', right_on = \"fid\")\n",
    "print(snappy_case_control_no_gc.shape)\n",
    "print(snappy_case_control_no_gc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snappy_case_control_no_gc.haplo_major.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y-LineageTracker Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrack = pd.read_table(f\"{OUTDIR}/output_ltracker/ltrack_hg19.lineageresult.txt\")\n",
    "\n",
    "ltrack['haplo_major'] = ltrack['Haplogroup'].str[0]\n",
    "ltrack.columns = ['id','haplo','keyhaplo','mutations','lineagetrack','haplo_major']\n",
    "ltrack['id'] = [i[:len(i)//2] for i in ltrack.id]\n",
    "print(ltrack.shape)\n",
    "print(ltrack.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrack_case_control_no_gc = pd.merge(left = ltrack[['id','haplo','haplo_major']], right = meta_merge,left_on = 'id', right_on = 'fid')\n",
    "print(ltrack_case_control_no_gc.shape)\n",
    "print(ltrack_case_control_no_gc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrack_case_control_no_gc.haplo_major.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup some stats functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi squared test for a specific haplotype\n",
    "def chi_square_for_haplogroup(haplo,haplo_col,df,prnt):\n",
    "    data = df.copy()\n",
    "    data.loc[data[haplo_col] != haplo,haplo_col] = 'not '+haplo\n",
    "\n",
    "    contingency_table = pd.crosstab(data[haplo_col], data['pheno'], margins = False) \n",
    "\n",
    "\n",
    "\n",
    "    g, p, dof, expctd = ss.chi2_contingency(contingency_table)\n",
    "    if prnt:\n",
    "        print(contingency_table)\n",
    "        print(g)\n",
    "        print(p)\n",
    "        print(dof)\n",
    "        print(expctd)\n",
    "        \n",
    "    return g, p, dof, expctd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression for specific full haplogroup\n",
    "def log_reg_for_haplogroup(haplo,df,prnt):\n",
    "    \n",
    "    \n",
    "    model = sm.GLM.from_formula(f\"pheno ~ {haplo} + AGE_BASELINE + pc1 + pc2 + pc3 + pc4 + pc5\",family = sm.families.Binomial(), data = df)\n",
    "    #model = sm.GLM.from_formula(f\"pheno ~ {haplo}\", data = data_no_gc_no_unknown)\n",
    "    results = model.fit()\n",
    "    if prnt:\n",
    "        print(results.summary())\n",
    "    results.summary()\n",
    "    \n",
    "    return results.pvalues[f'{haplo}'], results.params[haplo], results.bse[haplo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to count all haplogroups, do chi squared and logistic regression for each, and return a dataframe\n",
    "def run_chisq_and_log_reg(df,haplo_col_str, count_cutoff, prnt):\n",
    "    data_crosstab = pd.crosstab(df[haplo_col_str], df['pheno'], margins = False)\n",
    "    data_crosstab.columns = ['control','case']\n",
    "    data_crosstab_filter = data_crosstab.copy()\n",
    "    if(cutoff!=0):\n",
    "        data_crosstab_filter = data_crosstab[data_crosstab.control+data_crosstab.case>=count_cutoff]\n",
    "        \n",
    "    haplos = set(data_crosstab_filter.index.tolist())\n",
    "\n",
    "    #chi squared\n",
    "    chisq_results = data_crosstab_filter.copy()\n",
    "    chisq_results['p_chisq'] = 0.1\n",
    "    for h in haplos:\n",
    "        g, p, dof, expctd = chi_square_for_haplogroup(h,haplo_col_str,df,False)\n",
    "        chisq_results.at[h,'p_chisq'] = p\n",
    "    chisq_results.columns = ['controls','cases','p_chisq']\n",
    "    chisq_results = chisq_results.reset_index()\n",
    "\n",
    "\n",
    "    #logistic regression\n",
    "    df_ohe = df.copy()\n",
    "    df_ohe[haplo_col_str+'_orig'] = df_ohe[haplo_col_str]\n",
    "    df_ohe = pd.get_dummies(df_ohe, columns = [haplo_col_str])\n",
    "    df_ohe.pheno = df_ohe.pheno - 1\n",
    "\n",
    "\n",
    "\n",
    "    logreg_results = data_crosstab_filter.copy()\n",
    "    logreg_results['p_logreg'] = 0.1\n",
    "    for h in haplos:\n",
    "        p, beta,se = log_reg_for_haplogroup(f'{haplo_col_str}_{h}',df_ohe,False)\n",
    "        logreg_results.at[h,'p_logreg'] = p\n",
    "        logreg_results.at[h,'beta_logreg'] = beta\n",
    "        logreg_results.at[h,'se_logreg'] = se\n",
    "    logreg_results.columns = ['controls','cases','p_logreg','beta_logreg','se_logreg']\n",
    "    logreg_results = logreg_results.reset_index()\n",
    "\n",
    "\n",
    "    merge_results = pd.merge(left = logreg_results, right = chisq_results,left_on = [haplo_col_str,'controls','cases'], right_on = [haplo_col_str,'controls','cases'])\n",
    "\n",
    "    merge_results['case_freq'] = merge_results['cases'] / data_crosstab['case'].sum()\n",
    "    merge_results['control_freq'] = merge_results['controls'] / data_crosstab['control'].sum()\n",
    "\n",
    "    merge_results = merge_results[[haplo_col_str,'controls','control_freq','cases','case_freq','p_chisq','p_logreg','beta_logreg','se_logreg']]\n",
    "\n",
    "\n",
    "    if(prnt):\n",
    "        print(data_crosstab)\n",
    "        print(data_crosstab_filter.shape)\n",
    "        print(data_crosstab_filter)\n",
    "        print(len(haplos))\n",
    "        print(chisq_results)\n",
    "        print(df_ohe.shape)\n",
    "        print(df_ohe.columns)\n",
    "        print(logreg_results)\n",
    "        print(merge_results.shape)\n",
    "        \n",
    "    return merge_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yhaplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhaplo_cutoff_results = run_chisq_and_log_reg(yhaplo_case_control_no_gc,'haplo_long', cutoff, False)\n",
    "yhaplo_cutoff_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Snappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snappy_cutoff_results = run_chisq_and_log_reg(snappy_case_control_no_gc,'haplo', cutoff, False)\n",
    "snappy_cutoff_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Y-LineageTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrack_cutoff_results = run_chisq_and_log_reg(ltrack_case_control_no_gc,'haplo', cutoff, False)\n",
    "ltrack_cutoff_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and Compare Tool Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snappy_cutoff_results.columns = ['snappy_'+ c for c in snappy_cutoff_results.columns]\n",
    "print(snappy_cutoff_results.shape)\n",
    "print(snappy_cutoff_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhaplo_cutoff_results.columns = ['yhaplo_'+ c for c in yhaplo_cutoff_results.columns]\n",
    "print(yhaplo_cutoff_results.shape)\n",
    "print(yhaplo_cutoff_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrack_cutoff_results.columns = ['ltrack_'+ c for c in ltrack_cutoff_results.columns]\n",
    "print(ltrack_cutoff_results.shape)\n",
    "print(ltrack_cutoff_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_haplos = list(set(snappy_cutoff_results.snappy_haplo.tolist() + yhaplo_cutoff_results.yhaplo_haplo_long.tolist() + ltrack_cutoff_results.ltrack_haplo.tolist()))\n",
    "print(res_haplos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.DataFrame(data={'haplo':res_haplos})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.merge(left = merge, right = yhaplo_cutoff_results, left_on = 'haplo', right_on = 'yhaplo_haplo_long', how = 'outer')\n",
    "merge = pd.merge(left = merge, right = snappy_cutoff_results, left_on = 'haplo', right_on = 'snappy_haplo', how = 'outer')\n",
    "\n",
    "merge = pd.merge(left = merge, right = ltrack_cutoff_results, left_on = 'haplo', right_on = 'ltrack_haplo', how = 'outer')\n",
    "print(merge.shape)\n",
    "print(merge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge[(merge.snappy_p_logreg<0.05) | (merge.ltrack_p_logreg<0.05) | (merge.yhaplo_p_logreg<0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.to_csv(f\"{OUTDIR}/haplotype_full_lbd_case_control_no_gc_cutoff_50_new.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.6",
   "language": "python",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
