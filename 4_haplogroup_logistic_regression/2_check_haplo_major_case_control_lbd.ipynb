{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Chr Y Major (First Character) Haplogroups in LBD Cases and Controls\n",
    "- **Author(s)** - Frank Grenn\n",
    "- **Quick Description:** logistic regression for major haplogroups with AMPPD LBD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRKDIR = \"/PATH/chrY\"\n",
    "BFILEDIR = f\"{WRKDIR}/y_male_only_bfiles\"\n",
    "OUTDIR = f\"{WRKDIR}/output_male_hemizygous_only_het_filter_run\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam = pd.read_csv(f\"{BFILEDIR}/amppd_lbd_case_control_nogcs.fam\",sep=\"\\s+\",header=None)\n",
    "fam.columns = ['fid','iid','pid','mid','sex','pheno']\n",
    "print(fam.pheno.value_counts())\n",
    "\n",
    "print(fam.shape)\n",
    "print(fam.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam.pheno.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_pcs = pd.read_csv(f\"{BFILEDIR}/amppd_lbd_case_control_autosome_pcs.eigenvec\",sep=\"\\s+\",header=None)\n",
    "auto_pcs.columns = ['fid','iid'] + ['pc'+str(n) for n in range(1,21)]\n",
    "print(auto_pcs.shape)\n",
    "print(auto_pcs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"/PATH/AMPPD_releasev2_covariates_Feb2021.csv\")\n",
    "print(meta.shape)\n",
    "print(meta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just get yhaplo data for now because first character of haplogroup for all samples is the same between the yhaplo and snappy tools\n",
    "yhaplo = pd.read_csv(f\"{OUTDIR}/output_yhaplo/haplogroups.chrY_male_hemizygous_only_het_filter_hg19_final.txt\",sep=\"\\s+\",header=None)\n",
    "yhaplo.columns = ['id','haplo_short','haplo_short_rep_snp','haplo_long']\n",
    "yhaplo['haplo_major'] = yhaplo['haplo_long'].str[0]\n",
    "yhaplo['id'] = [i[:len(i)//2] for i in yhaplo.id]\n",
    "print(yhaplo.shape)\n",
    "print(yhaplo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge\n",
    "merge1 = pd.merge(left = fam[['fid','iid','sex','pheno']], right = auto_pcs, left_on = ['fid','iid'], right_on = ['fid','iid'])\n",
    "print(merge1.shape)\n",
    "merge2 = pd.merge(left = merge1, right = meta[['ID','AGE_BASELINE','LATEST_DX']], left_on = ['fid'], right_on = ['ID'])\n",
    "print(merge2.shape)\n",
    "merge3 = pd.merge(left = merge2, right = yhaplo[['id','haplo_major','haplo_long']], left_on = ['fid'], right_on = ['id'])\n",
    "print(merge3.shape)\n",
    "yhaplo_meta_df = merge3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhaplo_meta_df.LATEST_DX.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhaplo_meta_df.haplo_major.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhaplo_meta_df.pheno.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chi Squared Test For Case Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contingency table for chi squared later\n",
    "data_crosstab = pd.crosstab(yhaplo_meta_df['haplo_major'], yhaplo_meta_df['pheno'], margins = False) \n",
    "print(data_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crosstab.columns = ['control','case']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the table is counting correctly\n",
    "yhaplo_meta_df[(yhaplo_meta_df.pheno==1)& (yhaplo_meta_df.haplo_major=='R')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chi squared for speficic haplotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi squared test for a specific haplotype\n",
    "def chi_square_for_haplogroup(haplo,prnt):\n",
    "    data = yhaplo_meta_df.copy()\n",
    "    data.loc[data.haplo_major != haplo,'haplo_major'] = 'not '+haplo\n",
    "\n",
    "    contingency_table = pd.crosstab(data['haplo_major'], data['pheno'], margins = False) \n",
    "\n",
    "\n",
    "\n",
    "    g, p, dof, expctd = ss.chi2_contingency(contingency_table)\n",
    "    if prnt:\n",
    "        print(\"Observed:\")\n",
    "        print(contingency_table)\n",
    "        #print(g)\n",
    "        #print(p)\n",
    "        #print(dof)\n",
    "        print(\"Expected:\")\n",
    "        print(expctd)\n",
    "        \n",
    "    return g, p, dof, expctd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, p, dof, expctd = chi_square_for_haplogroup('R',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yhaplo_meta_df.copy()\n",
    "data.loc[data.haplo_major != 'R','haplo_major'] = 'not '+'R'\n",
    "\n",
    "contingency_table = pd.crosstab(data['haplo_major'], data['pheno'], margins = False) \n",
    "contingency_table.columns = ['control','case']\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haplos = set(yhaplo_meta_df['haplo_major'])\n",
    "haplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_control_chisq_results = data_crosstab.copy()\n",
    "case_control_chisq_results['p_chisq'] = 0.1\n",
    "for h in haplos:\n",
    "    print(h)\n",
    "    g, p, dof, expctd = chi_square_for_haplogroup(h,False)\n",
    "    case_control_chisq_results.at[h,'p_chisq'] = p\n",
    "case_control_chisq_results.columns = ['controls','cases','p_chisq']\n",
    "case_control_chisq_results = case_control_chisq_results.reset_index()\n",
    "print(case_control_chisq_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression for Case Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhaplo_meta_df_ohe = yhaplo_meta_df.copy()\n",
    "yhaplo_meta_df_ohe['haplo_major_orig'] = yhaplo_meta_df_ohe['haplo_major']\n",
    "yhaplo_meta_df_ohe = pd.get_dummies(yhaplo_meta_df_ohe, columns = ['haplo_major'])\n",
    "yhaplo_meta_df_ohe.pheno = yhaplo_meta_df_ohe.pheno - 1\n",
    "print(yhaplo_meta_df_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhaplo_meta_df_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression for specific major haplogroup\n",
    "def log_reg_for_haplogroup(haplo,prnt):\n",
    "    \n",
    "    \n",
    "    model = sm.GLM.from_formula(f\"pheno ~ {haplo} + AGE_BASELINE + pc1 + pc2 + pc3 + pc4 + pc5\",family = sm.families.Binomial(), data = yhaplo_meta_df_ohe)\n",
    "    #model = sm.GLM.from_formula(f\"pheno ~ {haplo}\", data = data_no_gc_no_unknown)\n",
    "    results = model.fit()\n",
    "    if prnt:\n",
    "        print(results.summary())\n",
    "    results.summary()\n",
    "    \n",
    "    return results.pvalues[haplo], results.params[haplo], results.bse[haplo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_control_logreg_results = data_crosstab.copy()\n",
    "case_control_logreg_results['p_logreg'] = 0.1\n",
    "for h in haplos:\n",
    "    print(h)\n",
    "    p, beta,se = log_reg_for_haplogroup(f'haplo_major_{h}',False)\n",
    "    case_control_logreg_results.at[h,'p_logreg'] = p\n",
    "    case_control_logreg_results.at[h,'beta_logreg'] = beta\n",
    "    case_control_logreg_results.at[h,'se_logreg'] = se\n",
    "case_control_logreg_results.columns = ['controls','cases','p_logreg','beta_logreg','se_logreg']\n",
    "case_control_logreg_results = case_control_logreg_results.reset_index()\n",
    "print(case_control_logreg_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combine and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results = pd.merge(left = case_control_logreg_results, right = case_control_chisq_results,left_on = ['haplo_major','controls','cases'], right_on = ['haplo_major','controls','cases'])\n",
    "print(merge_results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results['case_freq'] = merge_results['cases'] / sum(merge_results['cases'])\n",
    "merge_results['control_freq'] = merge_results['controls'] / sum(merge_results['controls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results = merge_results[['haplo_major','controls','control_freq','cases','case_freq','p_chisq','p_logreg','beta_logreg','se_logreg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results.to_csv(f\"{OUTDIR}/haplotype_major_lbd_case_control_new.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.6",
   "language": "python",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
